{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3061963-b15e-4446-81bc-6d8754baae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cca83d2-4337-4407-b918-db7b26163ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41399bb-3bc9-4a5f-ae5b-be66a0d5ea9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.6\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ae26bc-b206-4426-b13c-72303378c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"17.0.8.1\" 2023-08-24\n",
      "OpenJDK Runtime Environment (build 17.0.8.1+1-Ubuntu-0ubuntu122.04)\n",
      "OpenJDK 64-Bit Server VM (build 17.0.8.1+1-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "! java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682001dc-bc5e-458a-9d30-d4a7a161fed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/java\n"
     ]
    }
   ],
   "source": [
    "! which java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34fd4644-3611-459c-ba63-5b3faf310a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 3.5.0\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: /usr/local/spark/python\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e5e187-6fb7-48ac-8cec-1d6e7c6a7d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark_home\n",
    "\n",
    "import os\n",
    "os.environ.get('SPARK_HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b1b2ec3-7651-42c0-ab61-3fb130810b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAVA_HOME\n",
    "\n",
    "import os\n",
    "os.environ.get('JAVA_HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe9dc5f6-4b03-4c57-8f1e-f5b6fbef357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip:/usr/local/spark/python:'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pyrhonpath\n",
    "\n",
    "os.environ.get('PYTHONPATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12ded7ce-3495-4c31-bd3e-d6d6b9d13702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f9eb3c6-c852-4d00-8d23-3ea7bdb656e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ede75eb58ce9:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark example1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f88e388b790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "SparkSession.builder.appName('pyspark example1').getOrCreate() #chaining\n",
    "\n",
    "#SparkContext.Sparksseion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a7ec156-fe31-497c-8453-545b8b641985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ede75eb58ce9:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TestLocal</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7faa0c672e90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089bda96-1ac5-4a18-a194-bfdfda973af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate() #chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f4edb6-f0ca-4bd6-92e4-37616eb65c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ede75eb58ce9:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark example1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f88e388b790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaebe80d-b2d6-43b4-a856-382f49b93f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('Alice',1),('Bob',2),('Charlie',3)]\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9409d732-7312-49c4-b103-7a9009c33930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Value[1]'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataFrame 객체(분산객체)를 생성 <> 판다스의 데이터프레임이 아님  \n",
    "\n",
    "data1 = spark.createDataFrame(data, ['Name','Value'])\n",
    "data1[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc3ed77b-efd6-4d41-8317-fde553ee3339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|  Alice|    1|\n",
      "|    Bob|    2|\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a738bb74-9e39-4ec1-98df-fe1c0684edeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Value: bigint]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 #데이터프레임 객체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87288e-84f7-4b93-b9f4-7fc850753be6",
   "metadata": {},
   "source": [
    "# RDD 객체 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5900731-1cd8-43ae-a80d-b7609ef97636",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d0e29f6-d2e3-423e-b6d1-82711f0535cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[17] at readRDDFromFile at PythonRDD.scala:289"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1,2,3,4,5])\n",
    "rdd #RDD 객체 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "801eedb2-e15a-4dfb-afbe-098e8c8639d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5) #RDD 객체를 출력하는 함수 - n개를 지정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f32c759b-d7b9-4ccd-9b14-6c4a2bd775e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[25] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map 연산 : rdd 값으로 연산\n",
    "spuared_rdd = rdd.map(lambda x:x*x)\n",
    "spuared_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "000a48b6-b9ad-48f4-b275-ec691fd08570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spuared_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82523251-ffdd-40c5-af48-17cedfa8e8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spuared_rdd.collect() #전체값 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aff12b-8f34-46ea-9bf5-bfc7a4448af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9cccd-deec-4cfb-bfba-d6b00f18c416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad50b2-ea94-427f-a24c-ec6b131b1321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff86f5-2532-4f7e-9770-03a9a9137b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5eafb3-d65d-414e-b3d6-cf53dd6efefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestLocal\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.range(10).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
